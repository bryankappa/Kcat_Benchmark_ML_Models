{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, Descriptors\n",
    "import os\n",
    "os.chdir(\"..\")\n",
    "os.chdir(\"Preprocessing\")\n",
    "from preprocessing import *\n",
    "import selfies as sf\n",
    "\n",
    "df = preprocessing(\"C:\\\\Users\\Gilbert\\Documents\\BCB_Research\\Kcat_Benchmark_ML_Models\\Data\\kcat_transferase.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EC_number</th>\n",
       "      <th>Species</th>\n",
       "      <th>Compound</th>\n",
       "      <th>Compound_name</th>\n",
       "      <th>Amino_encoding</th>\n",
       "      <th>Kcat</th>\n",
       "      <th>unit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.1.1.1</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>C1=CC(=CN=C1)C(=O)N</td>\n",
       "      <td>Nicotinamide</td>\n",
       "      <td>MESGFTSKDTYLSHFNPRDFLEKYYKFGSRHSAESQILKHLLKNLF...</td>\n",
       "      <td>0.0410</td>\n",
       "      <td>s^(-1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.1.1.1</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>C1=CC(=CN=C1)C(=O)N</td>\n",
       "      <td>Nicotinamide</td>\n",
       "      <td>MESGFTSKDTYLSHFNPRDYLEKYYKFGSRHSAESQILKHLLKNLF...</td>\n",
       "      <td>1.0200</td>\n",
       "      <td>s^(-1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.1.1.1</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>C1=CC(=CN=C1)C(=O)N</td>\n",
       "      <td>Nicotinamide</td>\n",
       "      <td>MESGFTSKDTYLSHFNPRDYLEKYYKFGSRHSAESQILKHLLKNLF...</td>\n",
       "      <td>0.0830</td>\n",
       "      <td>s^(-1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.1.1.10</td>\n",
       "      <td>Brassica oleracea</td>\n",
       "      <td>C(CS)C(C(=O)O)N</td>\n",
       "      <td>L-Homocysteine</td>\n",
       "      <td>MGLEKKSALLEDLIEKCGGCAVVDGGFATQLEIHGAAINDPLWSAV...</td>\n",
       "      <td>0.0375</td>\n",
       "      <td>s^(-1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.1.1.10</td>\n",
       "      <td>Escherichia coli</td>\n",
       "      <td>C(CS)C(C(=O)O)N</td>\n",
       "      <td>L-Homocysteine</td>\n",
       "      <td>MSQNNPLRALLDKQDILLLDGAMATELEARGCNLADSLWSAKVLVE...</td>\n",
       "      <td>0.3800</td>\n",
       "      <td>s^(-1)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  EC_number            Species             Compound   Compound_name  \\\n",
       "0   2.1.1.1       Homo sapiens  C1=CC(=CN=C1)C(=O)N    Nicotinamide   \n",
       "1   2.1.1.1       Homo sapiens  C1=CC(=CN=C1)C(=O)N    Nicotinamide   \n",
       "2   2.1.1.1       Homo sapiens  C1=CC(=CN=C1)C(=O)N    Nicotinamide   \n",
       "3  2.1.1.10  Brassica oleracea      C(CS)C(C(=O)O)N  L-Homocysteine   \n",
       "4  2.1.1.10   Escherichia coli      C(CS)C(C(=O)O)N  L-Homocysteine   \n",
       "\n",
       "                                      Amino_encoding    Kcat    unit  \n",
       "0  MESGFTSKDTYLSHFNPRDFLEKYYKFGSRHSAESQILKHLLKNLF...  0.0410  s^(-1)  \n",
       "1  MESGFTSKDTYLSHFNPRDYLEKYYKFGSRHSAESQILKHLLKNLF...  1.0200  s^(-1)  \n",
       "2  MESGFTSKDTYLSHFNPRDYLEKYYKFGSRHSAESQILKHLLKNLF...  0.0830  s^(-1)  \n",
       "3  MGLEKKSALLEDLIEKCGGCAVVDGGFATQLEIHGAAINDPLWSAV...  0.0375  s^(-1)  \n",
       "4  MSQNNPLRALLDKQDILLLDGAMATELEARGCNLADSLWSAKVLVE...  0.3800  s^(-1)  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df.copy()\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[22:30:04] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:30:04] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    }
   ],
   "source": [
    "# Apply logarithmic transformation to 'Kcat'\n",
    "data[\"Kcat\"] = np.log10(data[\"Kcat\"])  # Applying log(x + 1) to handle zeros\n",
    "\n",
    "compound = data[\"Compound\"]\n",
    "\n",
    "data[\"smiles\"] = [Chem.MolFromSmiles(smiles) for smiles in compound]\n",
    "\n",
    "#encoding the species and EC_number\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "Ec_data = pd.get_dummies(data[\"EC_number\"], prefix=[\"EC\"])\n",
    "Ec_df = pd.DataFrame(Ec_data).astype(int)\n",
    "ec_pca = PCA(n_components=280)\n",
    "ec_principal_components = ec_pca.fit_transform(Ec_df)\n",
    "\n",
    "# Convert to DataFrame for convenience\n",
    "Ec_df = pd.DataFrame(data=ec_principal_components)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def molecular_weight(compound):\n",
    "    mol = Chem.MolFromSmiles(compound)\n",
    "    if mol:\n",
    "        return Descriptors.MolWt(mol)\n",
    "    else:\n",
    "        return none\n",
    "\n",
    "data[\"Molecular_Weight\"] = data[\"Compound\"].apply(molecular_weight)\n",
    "\n",
    "#apply log to molecular weight because it is not well distributed\n",
    "\n",
    "data[\"Molecular_Weight\"] = np.log10(data['Molecular_Weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "stats.probplot(data[\"Kcat\"], dist=\"norm\", plot=plt)\n",
    "plt.title('QQ Plot of Kcat values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the standard amino acids plus the padding character 'X'\n",
    "# amino_acids = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y', 'X']\n",
    "\n",
    "# # Find the length of the longest sequence\n",
    "# max_length = data['Amino_encoding'].str.len().max()\n",
    "\n",
    "# # Function to pad the sequences\n",
    "# def pad_sequence(seq, max_length):\n",
    "#     return seq.ljust(max_length, 'X')\n",
    "\n",
    "# # Apply padding to sequences\n",
    "# data['padded_sequence'] = data['Amino_encoding'].apply(lambda x: pad_sequence(x, max_length))\n",
    "\n",
    "# # One-hot encode the padded sequences\n",
    "# def one_hot_encode(seq):\n",
    "#     return [[1 if amino == aa else 0 for amino in amino_acids] for aa in seq]\n",
    "\n",
    "# encoded_sequences = data['padded_sequence'].apply(one_hot_encode)\n",
    "\n",
    "# # Convert the encoded sequences to a list of lists\n",
    "# encoded_list = encoded_sequences.apply(lambda x: [item for sublist in x for item in sublist]).tolist()\n",
    "\n",
    "# # Create a DataFrame from the flattened one-hot encoded list\n",
    "# encoded_df = pd.DataFrame(encoded_list)\n",
    "\n",
    "# # Rename columns for clarity\n",
    "# encoded_df.columns = [f'Pos_{i+1}_{aa}' for i in range(max_length) for aa in amino_acids]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create PCA object without limiting n_components\n",
    "pca = PCA()\n",
    "pca.fit(encoded_df)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_), marker='o', linestyle='--')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.title('Explained Variance by Components')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_95 = PCA(n_components=0.95)\n",
    "principalComponents_95 = pca_95.fit_transform(encoded_df)\n",
    "print(f\"Number of components to retain 95% variance: {pca_95.n_components_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_df = pd.read_csv(\"C:\\\\Users\\Gilbert\\Documents\\BCB_Research\\Kcat_Benchmark_ML_Models\\Data\\encoded_amino.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming encoded_df is your one-hot encoded data from before\n",
    "amino_pca = PCA(n_components=433)\n",
    "principal_components = amino_pca.fit_transform(encoded_df)\n",
    "\n",
    "# Convert to DataFrame for convenience\n",
    "amino_pca_df = pd.DataFrame(data=principal_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets add the SELFIES encoding into the result_df\n",
    "import selfies as sf\n",
    "\n",
    "# Define a function to convert SMILES to SELFIES\n",
    "def smiles_to_selfies(smiles_string):\n",
    "    try:\n",
    "        return sf.encoder(smiles_string)\n",
    "    except Exception as e:\n",
    "        print(f\"Error encoding {smiles_string}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Apply the function to the \"Compound\" column\n",
    "data[\"Selfies\"] = data[\"Compound\"].apply(smiles_to_selfies)\n",
    "\n",
    "data[\"Selfies\"] = data[\"Selfies\"].str.replace('.', '[.]')\n",
    "\n",
    "# let's encode the selfies string into one hot encoding.\n",
    "\n",
    "# Extract all unique symbols from the SELFIES\n",
    "def extract_symbols(selfies_string):\n",
    "    return sf.split_selfies(selfies_string)\n",
    "\n",
    "all_symbols = sorted(set(symbol for selfies in data[\"Selfies\"] for symbol in extract_symbols(selfies)))\n",
    "\n",
    "# One-Hot Encoding of the SELFIES strings\n",
    "def one_hot_selfies(selfies_string):\n",
    "    symbols = extract_symbols(selfies_string)\n",
    "    return [1 if symbol in symbols else 0 for symbol in all_symbols]\n",
    "\n",
    "# Creating a new DataFrame for one-hot encoded SELFIES\n",
    "one_hot_df = pd.DataFrame(data[\"Selfies\"].apply(one_hot_selfies).tolist(), columns=all_symbols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assuming encoded_df is your one-hot encoded data from before\n",
    "# sub_pca = PCA(n_components=2)\n",
    "# principal_components = sub_pca.fit_transform(one_hot_df)\n",
    "\n",
    "# # Convert to DataFrame for convenience\n",
    "# Selfies_one_hot = pd.DataFrame(data=principal_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming Data is your original dataframe\n",
    "result_df = pd.concat([one_hot_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.columns = result_df.columns.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 2.6479457402048547\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming data['Kcat'] is your target column\n",
    "X = one_hot_df\n",
    "y = data['Kcat']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "y_train_scaled = scaler.fit_transform(y_train.values.reshape(-1,1)).ravel()\n",
    "y_test_scaled = scaler.transform(y_test.values.reshape(-1,1)).ravel()\n",
    "\n",
    "# Create SVR model\n",
    "svr = SVR()\n",
    "\n",
    "# Train model\n",
    "svr.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "# Predict Kcat values\n",
    "y_pred = svr.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  1.3256818211825896\n",
      "MSE:  2.6479457402048547\n",
      "r2: 0.004215002272353274\n",
      "RMSE: 1.6272509764031038\n",
      "pearson: 0.09404259026772502\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "result = np.corrcoef(y_test, y_pred)[0,1]\n",
    "print('MAE: ', mean_absolute_error(y_test, y_pred))\n",
    "print('MSE: ', mean_squared_error(y_test, y_pred)) \n",
    "print('r2:', r2_score(y_test, y_pred))\n",
    "print('RMSE:', np.sqrt(mse))\n",
    "print(\"pearson:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('True vs. Predicted Kcat Values')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Create SVR model. You can adjust parameters as needed.\n",
    "svr_model = SVR(kernel='linear', C=300, gamma='auto', epsilon=0.1)\n",
    "\n",
    "# Choose number of folds; common choices are 5 or 10\n",
    "n_folds = 5\n",
    "\n",
    "# Cross validate\n",
    "scores = cross_val_score(svr_model, X, y, cv=n_folds, scoring='neg_mean_absolute_error')\n",
    "\n",
    "mae_scores = -scores\n",
    "\n",
    "print(f\"Mean MAE: {mae_scores.mean():.4f}\")\n",
    "print(f\"Standard Deviation of MAE: {mae_scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = make_regression(n_samples=1000, n_features=20, noise=0.1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "model = SVR()\n",
    "\n",
    "param_grid = {\n",
    "    'C': [1,10,100],\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'epsilon': [0.01, 0.1, 0.5, 1],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error', verbose=3, n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train_scaled, y_train_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_svr = grid_search.best_estimator_\n",
    "predictions = best_svr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bcb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
